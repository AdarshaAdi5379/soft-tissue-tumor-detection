{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7127ee-b02c-4f2b-949b-e1319e8a958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GM-UNet Tumor Segmentation - Jupyter Notebook\n",
    "\n",
    "# 1. Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# 2. Dataset Paths (update paths)\n",
    "IMAGE_DIR = \"dataset1/images\"\n",
    "MASK_DIR = \"dataset1/masks\"\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
    "\n",
    "# 3. Load Dataset\n",
    "def load_images_and_masks(image_dir, mask_dir, img_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    image_paths = sorted(glob(os.path.join(image_dir, \"*\")))\n",
    "    mask_paths  = sorted(glob(os.path.join(mask_dir, \"*\")))\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "        \n",
    "        mask = tf.keras.preprocessing.image.load_img(mask_path, target_size=img_size, color_mode=\"grayscale\")\n",
    "        mask = tf.keras.preprocessing.image.img_to_array(mask)\n",
    "        mask = mask / 255.0  # normalize to 0/1\n",
    "        mask = np.round(mask)  # ensure binary mask\n",
    "        \n",
    "        X.append(img)\n",
    "        Y.append(mask)\n",
    "    \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X, Y = load_images_and_masks(IMAGE_DIR, MASK_DIR)\n",
    "\n",
    "print(\"Dataset shape:\", X.shape, Y.shape)\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Visualize samples\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(3):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(2,3,i+4)\n",
    "    plt.imshow(Y_train[i].squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 6. GM-UNet Model Implementation\n",
    "def conv_block(x, filters, kernel_size=3, groups=2):\n",
    "    # Grouped convolution\n",
    "    group_list = []\n",
    "    input_channels = x.shape[-1]\n",
    "    group_channels = input_channels // groups\n",
    "    \n",
    "    for i in range(groups):\n",
    "        group = layers.Lambda(lambda z: z[..., i*group_channels:(i+1)*group_channels])(x)\n",
    "        group = layers.Conv2D(filters // groups, kernel_size, padding=\"same\")(group)\n",
    "        group_list.append(group)\n",
    "    \n",
    "    x = layers.Concatenate()(group_list)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def gm_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, 64)\n",
    "    p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 128)\n",
    "    p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 256)\n",
    "    p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 512)\n",
    "    p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "    u6 = layers.Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 512)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "    u7 = layers.Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 256)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "    u8 = layers.Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 128)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "    u9 = layers.Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 64)\n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, (1,1), activation=\"sigmoid\")(c9)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = gm_unet()\n",
    "model.summary()\n",
    "\n",
    "# 7. Loss and Metrics\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), \n",
    "              loss=\"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\", dice_coefficient])\n",
    "\n",
    "# 8. Training\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=20,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# 9. Training Graphs\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.legend(); plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend(); plt.title(\"Loss\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 10. Prediction Example\n",
    "def predict_and_visualize(idx=0):\n",
    "    img = np.expand_dims(X_val[idx], axis=0)\n",
    "    pred = model.predict(img)[0]\n",
    "    pred_mask = (pred > 0.5).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(X_val[idx]); plt.title(\"Image\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.imshow(Y_val[idx].squeeze(), cmap=\"gray\"); plt.title(\"Ground Truth\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,3); plt.imshow(pred_mask.squeeze(), cmap=\"gray\"); plt.title(\"Predicted\"); plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "predict_and_visualize(3)\n",
    "\n",
    "# 11. Save Trained Model\n",
    "model.save(\"gm_unet_tumor_segmentation.h5\")\n",
    "print(\"âœ… Model saved as gm_unet_tumor_segmentation.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a80ae-a74e-4808-87c8-eb9e12d407dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Load trained model\n",
    "model = load_model(\"gm_unet_tumor_segmentation.h5\",\n",
    "                   custom_objects={\"dice_coefficient\": lambda y_true, y_pred: 0})\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
    "\n",
    "# 2. Preprocess single image\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return np.expand_dims(img, axis=0), img\n",
    "\n",
    "# 3. Predict mask\n",
    "def predict_single_image(img_path):\n",
    "    img_input, original_img = preprocess_image(img_path)\n",
    "    pred = model.predict(img_input)[0]\n",
    "    pred_mask = (pred > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1); plt.imshow(original_img.astype(\"float32\")); plt.title(\"Input Image\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,2,2); plt.imshow(pred_mask.squeeze(), cmap=\"gray\"); plt.title(\"Predicted Mask\"); plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return pred_mask\n",
    "\n",
    "# Example usage\n",
    "predicted_mask = predict_single_image(\"1.PNG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
